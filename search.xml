<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Go语言基础学习笔记]]></title>
    <url>%2F2018%2F03%2F30%2FGo%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Nginx学习整理]]></title>
    <url>%2F2017%2F08%2F15%2FNginx%2F</url>
    <content type="text"><![CDATA[Nginx学习整理Nginx(“engine x”)是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的 Web和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。在高连接并发的情况下，Nginx是Apache服务器不错的替代品。 正向代理正向代理，我是一个用户,我访问不了某网站,但是我能访问一个代理服务器，这个代理服务器呢,他能访问那个我不能访问的网站，于是我先连上代理服务器,告诉他我需要那个无法访问网站的内容，代理服务器去取回来,然后返回给我。 正向代理 是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。 反向代理反向代理，用户访问 http://ooxx.me/readme，但ooxx.me上并不存在readme页面，他是偷偷从另外一台服务器上取回来,然后作为自己的内容吐给用户，但用户并不知情。 反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理 的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容 原本就是它自己的一样。 Nginx常用功能 Http代理，Nginx可以根据不同的正则匹配，采取不同的转发策略。 负载均衡，Nginx提供的负载均衡策略有2种：内置策略和扩展策略。内置策略为轮询，加权轮询，Ip hash。 web缓存，Nginx可以对不同的文件做不同的缓存处理。 Nginx安装 安装Nginx依赖的模块环境 gzip模块需要 zlib 库 rewrite模块需要 pcre 库 ssl 功能需要openssl库 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 下载Nginx安装包，地址http://nginx.org/en/download.html nginx-1.13.4.tar.gz，解压安装包 进入解压缩目录，./configure –prefix=/usr/local/webserver/nginx make &amp; make install Nginx配置文件详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121#运行用户user nobody;#启动进程,通常设置成和cpu的数量相等worker_processes 1;#全局错误日志及PID文件#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;#工作模式及连接数上限events &#123; #epoll是多路复用IO(I/O Multiplexing)中的一种方式, #仅用于linux2.6以上内核,可以大大提高nginx的性能 #使用epoll的I/O 模型。linux建议epoll，FreeBSD建议采用kqueue use epoll; #单个后台worker process进程的最大并发链接数 worker_connections 1024; # 并发总数是 worker_processes 和 worker_connections 的乘积 # 即 max_clients = worker_processes * worker_connections # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4 为什么 # 为什么上面反向代理要除以4，应该说是一个经验值 # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000 # worker_connections 值的设置跟物理内存大小有关 # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数 # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右 # 我们来看看360M内存的VPS可以打开的文件句柄数是多少： # $ cat /proc/sys/fs/file-max # 输出 34336 # 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内 # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置 # 使得并发总数小于操作系统可以打开的最大文件数目 # 其实质也就是根据主机的物理CPU和内存进行配置 # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。 # ulimit -SHn 65535 &#125;http &#123; #设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; #设定日志格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件， #对于普通应用，必须设为 on, #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off， #以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; #开启gzip压缩 gzip on; gzip_disable &quot;MSIE [1-6].&quot;; #设定请求缓冲 client_header_buffer_size 128k; large_client_header_buffers 4128k; #设定虚拟主机配置 server &#123; #侦听80端口 listen 80; #定义使用 www.nginx.cn访问 server_name www.nginx.cn; #定义服务器的默认网站根目录位置 root html; #设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; #默认请求 location / &#123; #定义首页索引文件的名称 index index.php index.html index.htm; &#125; # 定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; #过期30天，静态文件不怎么更新，过期可以设大一点， #如果频繁更新，则可以设置得小一点。 expires 30d; &#125; #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置. location ~ .php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; #禁止访问 .htxxx 文件 location ~ /.ht &#123; deny all; &#125; &#125;&#125; 负载均衡示例12345678910111213141516http &#123; upstream 项目名称 &#123; server 127.0.0.1:8000 weight=3; server 127.0.0.1:8001; server 127.0.0.1:8002; server 127.0.0.1:8003; &#125; server &#123; listen 80; server_name 域名; location / &#123; proxy_pass http://项目名称; &#125; &#125;&#125; 推荐一个地址：http://www.nginx.cn/doc/index.html]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop打包的几种方式]]></title>
    <url>%2F2017%2F08%2F14%2Fhadoop-jar%2F</url>
    <content type="text"><![CDATA[hadoop打包遇到的问题我们在写mapreduce的时候，使用maven打包，最终发现打包大小通常都是几十m。那么此时在想，我只吧自己的相关的打包就行了，引用的第三方的包直接使用集群来动态调入，这样就打包的大小就很小了。那么问题起来了，如何第三方常用的jar包放到哪里？又是怎么放的呢？ Hadoop打包的引用第三方的jar包的几种方式 把你所有的jar包都打包到一个包里，生成一个可2运行的包。 优点：直接在集群运行即可 缺点：jar包太大。不易维护 把引用的第三方的jar包放到hadoop的lib目录下，这样每个节点都的上传一次。 优点：打包小了，可以在集群直接运行 缺点：每个节点都的上传jar报，升级等不易维护 把jar包放到一台固定的机器上，使用libjars参数动态加载第三方jar 优点：只维护一处jar报即可 缺点：只能在存放jar机器执行Hadoop jar命令 事先把第三方jar包上传到hdfs上，使用job.addFileToClassPath方法进行注入。 优点：便于维护 缺点：需要在代码添加jar包。 把用到依赖的第三方包打包到lib文件夹，此次任务用不到的可以不添加。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark数据结构RDD介绍]]></title>
    <url>%2F2017%2F08%2F07%2FSparkRdd%2F</url>
    <content type="text"><![CDATA[Spark数据集RDD介绍RDD（Resilient Distributed Datasets），是一个容错的、并行的数据结构。可以让用户显示地将数据存储到磁盘或者内存中，并且可以及控制数据的分区。RDD的本质上是一个只读的分区集合。一个RDD可以包含多个分区，每个分区就是一个dataset片段。Spark实际上是把一个大的数据集，进行切割成N个小的数据集，并分给多个执行器（执行器数目小于数据集数），每个执行器负责各自的数据块的计算，最终把结果收集到一起。 RDD的两种操作 转换（transformation）和动作(Action)转换123456789101112131. 转换并且不会对RDD进行计算，它只是重新定义一个RDD。下面对转换的一些主要操作进行一些分析理解，下面以rdd(1,2,3)为例进行解释： 1. Map 对RDD中每一个元素进行一个操作，比如：对map里每个元素进行+1,变成（2，3，4），返回的是每个元素 2. flatmap 遍历当前的元素的每个元素，比如：对每一个行的元素进行分割操作,返回的是一个集合 3. filter 对rdd里元素进行过滤，比如：rdd.filter(x=&gt;x!=1),返回（2，3） 4. mapPartitions,应用于每个分区。返回的是一个（k,集合）的类型 5. union，rdd3=rdd1.union(rdd2),返回两个rdd的合并，不进行排重 6. groupByKey，对一个（k,v）进行聚合，返回（k,Seq&lt;V&gt;） 7. reduceByKey,对一个（k,v）进行分区，返回（k,Seq&lt;V&gt;）2. 动作，执行到Action的时候，是真正开始计算的时候。 1. reduce，对Rdd成员使用func进行reduce操作，接受两个参数，合并后返回一个值。func会并发执行 2. collect,将RDD读取到Driver程序。类型是一个数组 3. count，返回RDD的成员数量 4. foreach，对Rdd成员进行遍历 RDD依赖，宽依赖和窄依赖 宽依赖，子RDD对应父RDD只有一个 宽依赖，子rdd对于的父rdd有多个此时联系一下上边介绍的rdd的转换和操作，思考一下什么样的操作产生的RDD是宽依赖，什么样的操作产生的Rdd是窄依赖?回顾一下： map是针对每个元素的操作，那么它输出还是一个元素。所以map的转换后的Rdd是属于窄依赖。类似map的还有filter，union等 groupby的输出是（k,Seq(v)）类型，依赖多个父RDD，所以它属于宽依赖,类似的还有reduceby,join等 代码片段12345678910111213141516171819202122232425262728293031323334353637383940public static void main(String[] args)&#123; SparkConf sparkConf=new SparkConf().setMaster("local").setAppName("test"); JavaSparkContext jc=new JavaSparkContext(sparkConf); JavaRDD&lt;String&gt; text=jc.textFile("/Users/jing/Documents/text.txt"); //map JavaRDD&lt;String&gt; lines=text.map(new Function&lt;String, String&gt;() &#123; public String call(String v1) throws Exception &#123; System.out.println("v1 = [" + v1 + "]"); return v1; &#125; &#125;); //flatmap JavaRDD&lt;String&gt; words=text.flatMap(new FlatMapFunction&lt;String, String&gt;() &#123; public Iterator&lt;String&gt; call(String line) throws Exception &#123; System.out.println("line = [" + line + "]"); return Arrays.asList(line.split(" ")).iterator(); &#125; &#125;); //filter JavaRDD&lt;String&gt; filter=text.filter(new Function&lt;String, Boolean&gt;() &#123; public Boolean call(String v1) throws Exception &#123; return v1 != "1"; &#125; &#125;); //reduce words.reduce(new Function2&lt;String, String, String&gt;() &#123; public String call(String v1, String v2) throws Exception &#123; return v1 + v2; &#125; &#125;); words.collect(); &#125;]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
</search>
