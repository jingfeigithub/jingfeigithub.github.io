<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Go语言基础学习笔记]]></title>
    <url>%2F2018%2F03%2F30%2FGo%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Go语言基础学习笔记Go环境安装与开放工具选择 由于Go官网被墙，导致没有VPN下打不开，这里推荐一个GO中文社区的网站https://studygolang.com/dl 在这里下载自己对于系统的文件（我下载的是1.9.4版本的） 解压下载的文件到你安装的目录下 1tar -zxvf go1.9.4.darwin-amd64.tar 配置环境变量 12345678910111213141516 GOPATH=/Users/jing/Documents/soft/go PATH=$PATH:$GOPATH/bin ```[Go语言基础学习笔记](media/15223887372519/Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.md) 记得编译一下文件: source /etc/bashrc 4. 打开命令窗口：go version 如果返回对应的go版本，那么恭喜你安装成功了，反之，自行解决吧。### 对于开发工具，有很多 goland、vscode、eclipse、sublime Text等等，我还是比较喜欢jetbrains下的goland，goland的配置如下：有两个必须配置的属性：1. GOROOT 配置你安装的Go的路径2. GOPATH 该路径是指你开发go项目的工作空间路径，支持添加多个项目路径### ---## Go基础语法* Go的package用法 Go每个文件必须要有包的声明，并且必须在第一行，比如：package main 同一个路径下，只能存在一个package，一个package可以拆成多个源文件 如果要生成Go可执行程序，必须要有main的package包，且必须在该包下有main函数 1* Go的import用法 import可以导入源文件所依赖的package包 不允许导入源文件没有用到的包，否则编译器会报错（这个是不是比java .net强多了 哈哈） import的语法主要有两种： 123import &quot;package1&quot;import &quot;package2&quot;... 12345import (&quot;package1&quot;&quot;package2&quot; ...) import的别名 “.” “_”的用法 1231. 别名用户 import 别名 &quot;原始包名&quot;2. .的用法 import . &quot;fmt&quot; ,这样的话，在程序调用的时候就不需要fmt前缀了，直接使用fmt里的方法即可。（不推荐这样使用，不同包有相同的方法名就二逼了）3. _的用法，import _ &quot;fmt&quot;,_不会导入整个包，因此你无法使用该包里的其他函数，但是必定会执行fmt包里的init方法。该用法一般用在你不需要使用该包，但是你不得不注册该包供外部使用 12* Go的数据类型 整型：unit8(0-255) unit16(0-65536) unit32(0-4294967295) unit64(0-太大了懒得写了) int8(-128-127) int16（-32768-32767） int32 int64（太大了懒得写了） 浮点型：float32 float64 复数类型：complex64 complex128 布尔类型： bool ==&gt;true or false int所占的字节取决于系统位数，32系统位占4个字节，64位系统占8个字节 字符串类型：Go语言的字符串的字节使用UTF-8编码标识Unicode文本。 派生类型（先大概了解后续在一一学习）： 123456781. 指针类型2. 数组类型 eg: var array =[] string&#123;&quot;大象&quot;,&quot;大爷&quot;&#125;3. 结构体类型4. Channel类型5. 函数类型6. 切片类型7. interface类型8. Map类型 1* Go的变量声明 var 变量名称 变量数据类型 = 赋值 var 变量名称 变量数据类型 变量名称 = 赋值 变量名 := 赋值 分组声明 1234var (变量名 变量数据类型变量名2 变量数据类型) 声明多个变量：var a,b,c int = 1,2,3 全局变量必须使用var关键词，局部变量可以省略 ““ 下划线这个另类的特殊变量，只要赋值给，表示已经活到头了，over了，被回收了 Go类型转换格式：变量名称 [:]= 目标数据类型 (需要转换的变量) 切记：Go中不存在隐式转换，类型转换必须是显示转换1重点说明一下go里声明变量数据类型继承最近的变量数据类型 var a,b int = 1,2此时 a,b都为int类型var a,b int string = 1,”2” 这样写是绝对不支持的var ( a int b string )orvar a,b = 1,”222”咦，这样就对了嘛1* Go的变量作用域 在函数体内声明的变量称为局部变量，并且只在函数体内有效 全局变量，定义在函数外的变量，且必须使用var关键字。全局变量在该包名下所有位置有效。 1* Go的常量声明 显示声明：const 变量名称 变量数据类 = 赋值 隐式声明：const 变量名称 = 赋值 常量定义可以使用内置表达式定义，比如 len() ,unsafe.SizeOf()等等，但是呢，是不支持自己写的表达式滴 常量目前支持布尔类型、数字类型、字符串类型 1234567891011121314```const name = &quot;我是常量&quot;const name2 int = 2分组声明：const( name string = &quot;我是常量&quot; name2 int =2 )const( a = 1 b c = 2 )此时 a=1 b=1 c=2,神奇的事情出现了，*b默认和a等于同一个值* iota121. iota在你const关键字出现时将被重置为02. const中每新增一行常量声明将使iota计数+1 Go的运算符 123这个就不说了，java，.net里的都支持，比如+ - * / % += -=等|| &amp;&amp; 等 Go的控制语句 123456 var a int = 10if a &gt; 11 &#123; fmt.Println(&quot;大于11了&quot;)&#125;else &#123; fmt.Println(&quot;小于11了&quot;)&#125; else if else12345678var a int = 10 if a &gt; 11 &#123; fmt.Println(&quot;大于11了&quot;) &#125;else if a == 11 &#123; fmt.Println(&quot;等于11了&quot;) &#125;else&#123; fmt.Println(&quot;小于11了&quot;) &#125; 123456 switch a &#123; case 10: fmt.Println(&quot;等于10了&quot;) case 11: fmt.Println(&quot;等于11了&quot;) default: fmt.Println(&quot;啥都没等于&quot;)&#125; 12345678 for i:=10;i &lt; 11 ; i++ &#123; fmt.Println(i)&#125;var array =[] string&#123;&quot;大象&quot;,&quot;大爷&quot;&#125;for key,value:=range array&#123; fmt.Println(key) fmt.Println(value)&#125; 12345select &#123;case 10: fmt.Println(&quot;等于10啦&quot;)default: fmt.Println(&quot;毛都没有&quot;)&#125; Go里的函数1234567891011121314151617181920212223242526272829303132333435361. 声明格式 func 函数名称 (参数1，参数2，...) 返回类型 &#123; 函数体 &#125; ``` eg 嘛都不传，嘛都不返回: func test2() &#123; fmt.Println(&quot;test2&quot;) &#125; 嘛都不返回: func test3(a,b int) &#123; fmt.Println(reflect.TypeOf(a)) fmt.Println(reflect.TypeOf(b)) &#125; 返回一个值： func test2(a string,b int) int &#123; fmt.Println(a) fmt.Println(b) return 0 &#125; 返回多个值： func test3(a,b int) (int,int)&#123; fmt.Println(reflect.TypeOf(a)) fmt.Println(reflect.TypeOf(b)) return a,b &#125; 以上涉及到有参数传递的都是值传递，下面看看引用传递(不知道值传递和引用传递的可以去问问度娘) 引用传递: var a,b = 1,2 fmt.Println(&amp;a) fmt.Println(&amp;b) test5(&amp; a,&amp; b) func test5(a *int,b *int) &#123; var c int = 3 a = &amp; c b = &amp; c fmt.Println(a) fmt.Println(b) &#125; 1* Go的数组 声明方式：var 数组名称 [大小] 数组类型，eg：var array [6] int 数组初始化：var array [2] int {1,2} 数组访问：数组名称[下标]，eg: array[1] 得到的就是1123``` Go的多维数组1. var array [2][3] int &#123;&#123;1,2,3&#125;,&#123;4,5,6&#125;&#125;2. 访问： array[0][1] Go里的动态数组-切片（对数组的抽象） 123456781. 声明方式: var 变量名称 [] 数据类型（注意这里一定不设置长度，否则就是定长的数组啦）2. 使用make方法来创建切片，var 变量名称 [] 数据类型 = make([] 数据类型,长度) eg:var slice1 []int = make([]int,10)3. 初始化切片s,是数组arr的引用: var array =[]int &#123;1,2,3&#125; slice2 := array[0:2]4. 获取长度len(),eg: len(slice2)5. 获取切片的容量，eg: cap(slice2)6. 切片截取：slice2[0:1]7. 切片追加新的元素：slice2=append(slice2,1,2)8. 切片复制：拷贝 slice1 的内容到 slice2 ==&gt;&gt;&gt; copy(slice1,slice2) Go里的range(range 关键字用于for循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素) 123456 for _,变量名 := range 数组、map、切片 &#123; &#125; for _,name :=range array &#123; fmt.Println(name)&#125; 1234567for 索引变量,值变量名 := range 数组、map、切片 &#123; &#125;for index,name :=range array &#123; fmt.Println(index) fmt.Println(name)&#125; 1234 for index :=range array &#123; fmt.Println(index)&#125; Go的Map（无序的键值对的集合） 121. 声明方式：var 变量名称 map[key的数据类型] 元素的数据类型2. 使用make函数创建：变量名称 := make(map[key的数据类型] 元素的数据类型) var maptest map[int] string maptest = make(map[int]string) maptest[0] = &quot;尼玛&quot; maptest[1] = &quot;尼玛&quot; fmt.Println(maptest) 13. 删除元素：delete(maptest,&quot;尼玛&quot;) Go的指针（一个指针变量指向了一个值的内存地址） 1231. Go里在变量前使用&amp;,就可以得到变量的内存地址,*变量名就可以去到地址对应的值2. var 变量名称 *变量数据类型3. 指针的使用方式如下： var a int = 10 //声明实际变量 var zhizhen int //声明指针变量 zhizhen = &amp;a //指针变量赋值，指到实际变量的内存地址 zhizhen 就是对于的指针变量的值 fmt.Print(*zhizhen) //输出的值为：10 14. 空指针(当一个指针被定义后没有分配到任何实际变量时，它的值为：nil) Go的结构体(由一系列具有相同类型或不同类型的数据构成的数据集合） 12345678910111. 定义结构体： type 结构体名称 struct &#123; 成员 成员类型 ...&#125; ``` eg var nima NiMa nima.name = &quot;尼玛&quot; nima.age = 28 fmt.Println(nima.name) fmt.Println(nima.age) type NiMa struct &#123; name string age int &#125; 1* Go里的接口 接口声明方式 1234567891011type 接口名称 interface&#123; 成员名称 返回值类型&#125;//定义结构体type 机构体名称 struct&#123;&#125;//实现接口func (结构体类型 变量) 接口方法() [返回值类型]&#123;&#125; 123456789101112131415var sb ITestsb=new(ImplTest)sb.hello()type ITest interface &#123; hello() int &#125; type ImplTest struct &#123; &#125; func (impl ImplTest) hello() int &#123; fmt.Println(0) return 0 &#125; ```]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx学习整理]]></title>
    <url>%2F2017%2F08%2F15%2FNginx%2F</url>
    <content type="text"><![CDATA[Nginx学习整理Nginx(“engine x”)是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的 Web和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。在高连接并发的情况下，Nginx是Apache服务器不错的替代品。 正向代理正向代理，我是一个用户,我访问不了某网站,但是我能访问一个代理服务器，这个代理服务器呢,他能访问那个我不能访问的网站，于是我先连上代理服务器,告诉他我需要那个无法访问网站的内容，代理服务器去取回来,然后返回给我。 正向代理 是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。 反向代理反向代理，用户访问 http://ooxx.me/readme，但ooxx.me上并不存在readme页面，他是偷偷从另外一台服务器上取回来,然后作为自己的内容吐给用户，但用户并不知情。 反向代理正好相反，对于客户端而言它就像是原始服务器，并且客户端不需要进行任何特别的设置。客户端向反向代理 的命名空间(name-space)中的内容发送普通请求，接着反向代理将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容 原本就是它自己的一样。 Nginx常用功能 Http代理，Nginx可以根据不同的正则匹配，采取不同的转发策略。 负载均衡，Nginx提供的负载均衡策略有2种：内置策略和扩展策略。内置策略为轮询，加权轮询，Ip hash。 web缓存，Nginx可以对不同的文件做不同的缓存处理。 Nginx安装 安装Nginx依赖的模块环境 gzip模块需要 zlib 库 rewrite模块需要 pcre 库 ssl 功能需要openssl库 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 下载Nginx安装包，地址http://nginx.org/en/download.html nginx-1.13.4.tar.gz，解压安装包 进入解压缩目录，./configure –prefix=/usr/local/webserver/nginx make &amp; make install Nginx配置文件详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121#运行用户user nobody;#启动进程,通常设置成和cpu的数量相等worker_processes 1;#全局错误日志及PID文件#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;#工作模式及连接数上限events &#123; #epoll是多路复用IO(I/O Multiplexing)中的一种方式, #仅用于linux2.6以上内核,可以大大提高nginx的性能 #使用epoll的I/O 模型。linux建议epoll，FreeBSD建议采用kqueue use epoll; #单个后台worker process进程的最大并发链接数 worker_connections 1024; # 并发总数是 worker_processes 和 worker_connections 的乘积 # 即 max_clients = worker_processes * worker_connections # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4 为什么 # 为什么上面反向代理要除以4，应该说是一个经验值 # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000 # worker_connections 值的设置跟物理内存大小有关 # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数 # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右 # 我们来看看360M内存的VPS可以打开的文件句柄数是多少： # $ cat /proc/sys/fs/file-max # 输出 34336 # 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内 # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置 # 使得并发总数小于操作系统可以打开的最大文件数目 # 其实质也就是根据主机的物理CPU和内存进行配置 # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。 # ulimit -SHn 65535 &#125;http &#123; #设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; #设定日志格式 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log logs/access.log main; #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件， #对于普通应用，必须设为 on, #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off， #以平衡磁盘与网络I/O处理速度，降低系统的uptime. sendfile on; #tcp_nopush on; #连接超时时间 #keepalive_timeout 0; keepalive_timeout 65; tcp_nodelay on; #开启gzip压缩 gzip on; gzip_disable &quot;MSIE [1-6].&quot;; #设定请求缓冲 client_header_buffer_size 128k; large_client_header_buffers 4128k; #设定虚拟主机配置 server &#123; #侦听80端口 listen 80; #定义使用 www.nginx.cn访问 server_name www.nginx.cn; #定义服务器的默认网站根目录位置 root html; #设定本虚拟主机的访问日志 access_log logs/nginx.access.log main; #默认请求 location / &#123; #定义首页索引文件的名称 index index.php index.html index.htm; &#125; # 定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; #过期30天，静态文件不怎么更新，过期可以设大一点， #如果频繁更新，则可以设置得小一点。 expires 30d; &#125; #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置. location ~ .php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; #禁止访问 .htxxx 文件 location ~ /.ht &#123; deny all; &#125; &#125;&#125; 负载均衡示例12345678910111213141516http &#123; upstream 项目名称 &#123; server 127.0.0.1:8000 weight=3; server 127.0.0.1:8001; server 127.0.0.1:8002; server 127.0.0.1:8003; &#125; server &#123; listen 80; server_name 域名; location / &#123; proxy_pass http://项目名称; &#125; &#125;&#125; 推荐一个地址：http://www.nginx.cn/doc/index.html]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadoop打包的几种方式]]></title>
    <url>%2F2017%2F08%2F14%2Fhadoop-jar%2F</url>
    <content type="text"><![CDATA[hadoop打包遇到的问题我们在写mapreduce的时候，使用maven打包，最终发现打包大小通常都是几十m。那么此时在想，我只吧自己的相关的打包就行了，引用的第三方的包直接使用集群来动态调入，这样就打包的大小就很小了。那么问题起来了，如何第三方常用的jar包放到哪里？又是怎么放的呢？ Hadoop打包的引用第三方的jar包的几种方式 把你所有的jar包都打包到一个包里，生成一个可2运行的包。 优点：直接在集群运行即可 缺点：jar包太大。不易维护 把引用的第三方的jar包放到hadoop的lib目录下，这样每个节点都的上传一次。 优点：打包小了，可以在集群直接运行 缺点：每个节点都的上传jar报，升级等不易维护 把jar包放到一台固定的机器上，使用libjars参数动态加载第三方jar 优点：只维护一处jar报即可 缺点：只能在存放jar机器执行Hadoop jar命令 事先把第三方jar包上传到hdfs上，使用job.addFileToClassPath方法进行注入。 优点：便于维护 缺点：需要在代码添加jar包。 把用到依赖的第三方包打包到lib文件夹，此次任务用不到的可以不添加。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark数据结构RDD介绍]]></title>
    <url>%2F2017%2F08%2F07%2FSparkRdd%2F</url>
    <content type="text"><![CDATA[Spark数据集RDD介绍RDD（Resilient Distributed Datasets），是一个容错的、并行的数据结构。可以让用户显示地将数据存储到磁盘或者内存中，并且可以及控制数据的分区。RDD的本质上是一个只读的分区集合。一个RDD可以包含多个分区，每个分区就是一个dataset片段。Spark实际上是把一个大的数据集，进行切割成N个小的数据集，并分给多个执行器（执行器数目小于数据集数），每个执行器负责各自的数据块的计算，最终把结果收集到一起。 RDD的两种操作 转换（transformation）和动作(Action)转换123456789101112131. 转换并且不会对RDD进行计算，它只是重新定义一个RDD。下面对转换的一些主要操作进行一些分析理解，下面以rdd(1,2,3)为例进行解释： 1. Map 对RDD中每一个元素进行一个操作，比如：对map里每个元素进行+1,变成（2，3，4），返回的是每个元素 2. flatmap 遍历当前的元素的每个元素，比如：对每一个行的元素进行分割操作,返回的是一个集合 3. filter 对rdd里元素进行过滤，比如：rdd.filter(x=&gt;x!=1),返回（2，3） 4. mapPartitions,应用于每个分区。返回的是一个（k,集合）的类型 5. union，rdd3=rdd1.union(rdd2),返回两个rdd的合并，不进行排重 6. groupByKey，对一个（k,v）进行聚合，返回（k,Seq&lt;V&gt;） 7. reduceByKey,对一个（k,v）进行分区，返回（k,Seq&lt;V&gt;）2. 动作，执行到Action的时候，是真正开始计算的时候。 1. reduce，对Rdd成员使用func进行reduce操作，接受两个参数，合并后返回一个值。func会并发执行 2. collect,将RDD读取到Driver程序。类型是一个数组 3. count，返回RDD的成员数量 4. foreach，对Rdd成员进行遍历 RDD依赖，宽依赖和窄依赖 宽依赖，子RDD对应父RDD只有一个 宽依赖，子rdd对于的父rdd有多个此时联系一下上边介绍的rdd的转换和操作，思考一下什么样的操作产生的RDD是宽依赖，什么样的操作产生的Rdd是窄依赖?回顾一下： map是针对每个元素的操作，那么它输出还是一个元素。所以map的转换后的Rdd是属于窄依赖。类似map的还有filter，union等 groupby的输出是（k,Seq(v)）类型，依赖多个父RDD，所以它属于宽依赖,类似的还有reduceby,join等 代码片段12345678910111213141516171819202122232425262728293031323334353637383940public static void main(String[] args)&#123; SparkConf sparkConf=new SparkConf().setMaster("local").setAppName("test"); JavaSparkContext jc=new JavaSparkContext(sparkConf); JavaRDD&lt;String&gt; text=jc.textFile("/Users/jing/Documents/text.txt"); //map JavaRDD&lt;String&gt; lines=text.map(new Function&lt;String, String&gt;() &#123; public String call(String v1) throws Exception &#123; System.out.println("v1 = [" + v1 + "]"); return v1; &#125; &#125;); //flatmap JavaRDD&lt;String&gt; words=text.flatMap(new FlatMapFunction&lt;String, String&gt;() &#123; public Iterator&lt;String&gt; call(String line) throws Exception &#123; System.out.println("line = [" + line + "]"); return Arrays.asList(line.split(" ")).iterator(); &#125; &#125;); //filter JavaRDD&lt;String&gt; filter=text.filter(new Function&lt;String, Boolean&gt;() &#123; public Boolean call(String v1) throws Exception &#123; return v1 != "1"; &#125; &#125;); //reduce words.reduce(new Function2&lt;String, String, String&gt;() &#123; public String call(String v1, String v2) throws Exception &#123; return v1 + v2; &#125; &#125;); words.collect(); &#125;]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
</search>
